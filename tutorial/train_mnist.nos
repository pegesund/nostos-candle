# Train LSTM on MNIST digit classification (Nostos + Candle).
#
# Treats each 28x28 image as a sequence of 28 rows (28 time steps, 28-dim input).
# Model: LSTM(28, 128) -> linear(128, 10) on last hidden state.
#
# Run: nostos --use candle tutorial/train_mnist.nos
use candle.*

# Forward pass: LSTM over 28 rows, take last hidden state, project to 10 classes
predict(lstm: LSTM, wOut: Tensor, images: Tensor) -> Tensor = {
    hidden = lstmSeq(lstm, images)       # [batch, 28, 128]
    last = hidden.lastOf(1)              # [batch, 128]
    linear(last, wOut)                   # [batch, 10]
}

# Evaluate one batch: forward pass, argmax, count correct
evalBatch(lstm: LSTM, wOut: Tensor, images: Tensor, labels: Tensor) -> Int = {
    logits = predict(lstm, wOut, images)
    preds = argmax(logits, 1).squeeze(1)
    countEqual(preds, labels)
}

main() = {
    println("Loading MNIST from safetensors...")
    data = loadSafetensors("tutorial/data/mnist.safetensors")
    trainImages = getTensor(data, "train_images")   # [60000, 28, 28]
    trainLabels = getTensor(data, "train_labels")    # [60000]
    testImages = getTensor(data, "test_images")      # [10000, 28, 28]
    testLabels = getTensor(data, "test_labels")      # [10000]

    nTrain = tensorShape(trainImages)[0]
    nTest = tensorShape(testImages)[0]

    println("  Train: " ++ show(tensorShape(trainImages)))
    println("  Test:  " ++ show(tensorShape(testImages)))

    # Create trainable model
    params = paramMapCreate()
    lstm = lstmTrainable(params, 28, 128)
    wOut = paramRandn(params, [10, 128])

    opt = adam(params, 0.001)

    batchSize = 128
    numEpochs = 3

    println("")
    println("Training LSTM on MNIST:")
    println("  Model: LSTM(28, 128) -> linear(128, 10)")
    println("  Optimizer: Adam(lr=0.001)")
    println("  Batch size: " ++ show(batchSize) ++ ", Epochs: " ++ show(numEpochs))
    println("")

    var epoch = 0
    while epoch < numEpochs {
        var totalLoss = 0.0
        var nBatches = 0
        var start = 0

        while start < nTrain {
            curBatch = min(batchSize, nTrain - start)
            images = trainImages.sliceDim(0, start, curBatch)
            labels = trainLabels.sliceDim(0, start, curBatch)

            logits = predict(lstm, wOut, images)
            loss = crossEntropyLoss(logits, labels)
            lv = trainStep(opt, loss)

            totalLoss = totalLoss + lv
            nBatches = nBatches + 1
            start = start + batchSize
        }

        avgLoss = totalLoss / toFloat(nBatches)
        println("  Epoch " ++ show(epoch + 1) ++ "/" ++ show(numEpochs) ++ " - avg loss: " ++ show(avgLoss))
        epoch = epoch + 1
    }

    # Evaluate on test set
    println("")
    println("Evaluating on test set...")
    var correct = 0
    var testStart = 0
    evalBatchSize = 100

    while testStart < nTest {
        images = testImages.sliceDim(0, testStart, evalBatchSize)
        labels = testLabels.sliceDim(0, testStart, evalBatchSize)
        correct = correct + evalBatch(lstm, wOut, images, labels)
        testStart = testStart + evalBatchSize
    }

    pct = toFloat(correct) * 100.0 / toFloat(nTest)
    println("  Test accuracy: " ++ show(correct) ++ "/" ++ show(nTest) ++ " = " ++ show(pct) ++ "%")

    0
}
