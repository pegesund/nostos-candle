# ModernBERT Implementation with Pretrained Weights
# Implements: RoPE, GeGLU, Pre-Norm, Fused QKV
# Run: nostos --use candle examples/13_modernbert.nos

use candle.*

# =============================================================================
# Tokenization (isolated to avoid type inference issues)
# =============================================================================

getTokenIds(text) = {
    tok = loadTokenizer("/home/user/nostos-candle/models/modernbert-tokenizer.json")
    encode(tok, text)
}

# =============================================================================
# Attention Helpers
# =============================================================================

splitHeads(x, numHeads) = {
    shape = tensorShape(x)
    batch = shape[0]
    seq = shape[1]
    hidden = shape[2]
    headDim = hidden / numHeads
    reshaped = reshape(x, [batch, seq, numHeads, headDim])
    swapDims(reshaped, 1, 2)
}

mergeHeads(x) = {
    shape = tensorShape(x)
    batch = shape[0]
    numHeads = shape[1]
    seq = shape[2]
    headDim = shape[3]
    hidden = numHeads * headDim
    transposed = swapDims(x, 1, 2)
    reshape(transposed, [batch, seq, hidden])
}

applyRopeToQK(x, cos, sin) = {
    shape = tensorShape(x)
    headDim = shape[3]
    halfDim = headDim / 2
    x1 = narrow(x, 3, 0, halfDim)
    x2 = narrow(x, 3, halfDim, halfDim)
    cosHalf = narrow(cos, 1, 0, halfDim)
    sinHalf = narrow(sin, 1, 0, halfDim)
    cosB = unsqueeze(unsqueeze(cosHalf, 0), 0)
    sinB = unsqueeze(unsqueeze(sinHalf, 0), 0)
    rotX1 = tensorSub(tensorMul(x1, cosB), tensorMul(x2, sinB))
    rotX2 = tensorAdd(tensorMul(x1, sinB), tensorMul(x2, cosB))
    cat([rotX1, rotX2], 3)
}

# =============================================================================
# ModernBERT Components
# =============================================================================

modernBertAttention(x, wQKV, wO, cos, sin, numHeads, headDimF) = {
    qkv = linear(x, wQKV)
    shape = tensorShape(qkv)
    hidden = shape[2] / 3
    q = narrow(qkv, 2, 0, hidden)
    k = narrow(qkv, 2, hidden, hidden)
    v = narrow(qkv, 2, hidden * 2, hidden)
    qHeads = contiguous(splitHeads(q, numHeads))
    kHeads = contiguous(splitHeads(k, numHeads))
    vHeads = contiguous(splitHeads(v, numHeads))
    qRope = applyRopeToQK(qHeads, cos, sin)
    kRope = applyRopeToQK(kHeads, cos, sin)
    scale = tensorSqrt(fromList([headDimF]))
    kT = contiguous(swapDims(kRope, 2, 3))
    scores = matmul(qRope, kT)
    scaledScores = tensorDiv(scores, scale)
    attnWeights = softmax(scaledScores, 3)
    attnOutput = matmul(attnWeights, vHeads)
    merged = mergeHeads(contiguous(attnOutput))
    linear(merged, wO)
}

modernBertMLP(x, wI, wO) = {
    gateUp = linear(x, wI)
    shape = tensorShape(gateUp)
    intermediate = shape[2] / 2
    gate = narrow(gateUp, 2, 0, intermediate)
    up = narrow(gateUp, 2, intermediate, intermediate)
    hidden = geglu(gate, up)
    linear(hidden, wO)
}

modernBertLayer0(x, wQKV, wO, mlpNormW, wI, wO2, cos, sin, numHeads, headDimF, hidden) = {
    attnOut = modernBertAttention(x, wQKV, wO, cos, sin, numHeads, headDimF)
    hidden1 = tensorAdd(x, attnOut)
    zerosBias = zeros([hidden])
    mlpIn = layerNorm(hidden1, mlpNormW, zerosBias)
    mlpOut = modernBertMLP(mlpIn, wI, wO2)
    tensorAdd(hidden1, mlpOut)
}

modernBertLayerN(x, attnNormW, wQKV, wO, mlpNormW, wI, wO2, cos, sin, numHeads, headDimF, hidden) = {
    zerosBias = zeros([hidden])
    attnIn = layerNorm(x, attnNormW, zerosBias)
    attnOut = modernBertAttention(attnIn, wQKV, wO, cos, sin, numHeads, headDimF)
    hidden1 = tensorAdd(x, attnOut)
    mlpIn = layerNorm(hidden1, mlpNormW, zerosBias)
    mlpOut = modernBertMLP(mlpIn, wI, wO2)
    tensorAdd(hidden1, mlpOut)
}

# =============================================================================
# Weight Loading Helpers
# =============================================================================

loadLayer0(model) = {
    [
        getTensor(model, "model.layers.0.attn.Wqkv.weight"),
        getTensor(model, "model.layers.0.attn.Wo.weight"),
        getTensor(model, "model.layers.0.mlp_norm.weight"),
        getTensor(model, "model.layers.0.mlp.Wi.weight"),
        getTensor(model, "model.layers.0.mlp.Wo.weight")
    ]
}

loadLayer1(model) = {
    [
        getTensor(model, "model.layers.1.attn_norm.weight"),
        getTensor(model, "model.layers.1.attn.Wqkv.weight"),
        getTensor(model, "model.layers.1.attn.Wo.weight"),
        getTensor(model, "model.layers.1.mlp_norm.weight"),
        getTensor(model, "model.layers.1.mlp.Wi.weight"),
        getTensor(model, "model.layers.1.mlp.Wo.weight")
    ]
}

loadLayer2(model) = {
    [
        getTensor(model, "model.layers.2.attn_norm.weight"),
        getTensor(model, "model.layers.2.attn.Wqkv.weight"),
        getTensor(model, "model.layers.2.attn.Wo.weight"),
        getTensor(model, "model.layers.2.mlp_norm.weight"),
        getTensor(model, "model.layers.2.mlp.Wi.weight"),
        getTensor(model, "model.layers.2.mlp.Wo.weight")
    ]
}

# =============================================================================
# Forward Pass Helpers
# =============================================================================

runEmbeddings(tokenTensor, model) = {
    tokEmb = getTensor(model, "model.embeddings.tok_embeddings.weight")
    embNormW = getTensor(model, "model.embeddings.norm.weight")
    embedded = embedding(tokenTensor, tokEmb)
    println("1. Token Embeddings - Shape:")
    println(tensorShape(embedded))
    printFirst5CLS(embedded, "   (before norm)")
    zerosBias = zeros([768])
    embNormed = layerNorm(embedded, embNormW, zerosBias)
    println("\n2. After Embedding Norm")
    printFirst5CLS(embNormed, "")
    embNormed
}

printFirst5CLS(x, suffix) = {
    slice = narrow(narrow(x, 0, 0, 1), 1, 0, 1)
    first = squeeze(squeeze(slice, 0), 0)
    println("   First 5 values of CLS" ++ suffix ++ ":")
    println(toList(narrow(first, 0, 0, 5)))
}

runLayer0(x, model, cosGlobal, sinGlobal) = {
    weights = loadLayer0(model)
    result = modernBertLayer0(x, weights[0], weights[1], weights[2], weights[3], weights[4], cosGlobal, sinGlobal, 12, 64.0, 768)
    println("\n3. After Layer 0 (global attention)")
    printFirst5CLS(result, "")
    result
}

runLayer1(x, model, cosLocal, sinLocal) = {
    weights = loadLayer1(model)
    result = modernBertLayerN(x, weights[0], weights[1], weights[2], weights[3], weights[4], weights[5], cosLocal, sinLocal, 12, 64.0, 768)
    println("\n4. After Layer 1 (local attention)")
    printFirst5CLS(result, "")
    result
}

runLayer2(x, model, cosLocal, sinLocal) = {
    weights = loadLayer2(model)
    result = modernBertLayerN(x, weights[0], weights[1], weights[2], weights[3], weights[4], weights[5], cosLocal, sinLocal, 12, 64.0, 768)
    println("\n5. After Layer 2 (local attention)")
    printFirst5CLS(result, "")
    result
}

# =============================================================================
# Main
# =============================================================================

main() = {
    println("=== ModernBERT Implementation ===")
    println("Model: answerdotai/ModernBERT-base\n")

    # Tokenize
    testText = "hello world"
    println("Input: \"" ++ testText ++ "\"")
    tokenIds = getTokenIds(testText)
    println("Token IDs:")
    println(tokenIds)

    # Convert to tensor
    tokenTensor = unsqueeze(fromIntList(tokenIds), 0)
    println("Token tensor shape:")
    println(tensorShape(tokenTensor))
    seqLen = (tensorShape(tokenTensor))[1]

    # Load model
    println("\nLoading safetensors...")
    model = loadSafetensors("/home/user/nostos-candle/models/modernbert-base.safetensors")
    println("Model loaded!")

    # Compute RoPE frequencies
    println("Computing RoPE frequencies...")
    ropeGlobal = ropeFreqs(seqLen, 64, 160000.0)
    ropeLocal = ropeFreqs(seqLen, 64, 10000.0)
    println("RoPE computed!\n")

    # Forward pass
    println("--- Forward Pass ---\n")

    # Embeddings
    embNormed = runEmbeddings(tokenTensor, model)

    # Layers
    h0 = runLayer0(embNormed, model, ropeGlobal[0], ropeGlobal[1])
    h1 = runLayer1(h0, model, ropeLocal[0], ropeLocal[1])
    h2 = runLayer2(h1, model, ropeLocal[0], ropeLocal[1])

    println("\n=== ModernBERT Partial Implementation Complete ===")
    println("(Running first 3 layers for verification)")

    0
}
